# XML-Parse-GEO-NCBI
Script to download and parse the XMLs files (MINiML formatted file) referring to experiments (GSEs) deposited in the public database (GENE EXPRESSION OMNIBUS - GEO/NCB) 

We have three main scripts:

1) get-xml.py (to download the xmls files related to each series from GEO-NCBI)
2) main-parse.py (parse xmls files using several 'child' and 'subchild' tags
3) main-srx.py (parse xmls files to recover the SRX information to use it to get the SRR ids)
4) main-srr.py (webscrapping to recover the SRR Ids for each sample (GSM)) 


##########################################################################################################################################################
1) Download the XMLs files

You should pass as the first argument a list of address (i.e ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE156nnn/GSE156377/miniml/GSE156377_family.xml.tgz) andthe root path as the second argument (i.e $PWD/GEO). A new subdirectory will be created every 300 files downloaded within the directory specified on the command line (i.e $PWD/GEO/GEO_1).


The command line:
python get-xml.py list-fulladrs-8479.txt /home/frosig/scratch/chip-seq-ihec-test/XML-files-webscrp/GEO-xml-query-genomebinding-8479
##########################################################################################################################################################


2) Parsing the XMLs files

This script (parser_xml.py) will extract the follow information from the XMLs downloaded:

Release Date
Title
Library-Strategy (i.e ChIP-Seq, RNA-Seq)
Plataform-Ref (GPL)
Target information (related with chip_antibody and its variation - i.e antibody, chip_antibody, ChIP, chip-antibody, antibody target) 
Organism
ChIP catalog (and variations - i.e catalogue_number, chip antibody cat. #)
Cell line
Cell Type


The tsv output file after this step (xml_out.tsv) will be passed to df_xml.py script. This script will organize the columns with each extracted informationand the output is a csv file (output_df_xml.csv).



The command line:
python main-parser.py -p $PATH_TO_DIRECTORY_XML -o xml_out.tsv -d PATH_DESTINY_FINAL_OUTPUT

To run via slurm:

#!/bin/bash
#SBATCH --time=02:00:00 # changeable 
#SBATCH --account=
#SBATCH --cpus-per-task=4 #example
#SBATCH --mem=5G #example
#SBATCH --job-name=parse-xml


module load python/3.8.0
virtualenv --no-download $SLURM_TMPDIR/env
source $SLURM_TMPDIR/env/bin/activate
pip install --no-index --upgrade pip

pip install --no-index -r requirements.txt

python main-parser.py -p $PATH_TO_DIRECTORY_XML -o xml_out.tsv -d PATH_DESTINY_FINAL_OUTPUT.csv

######################################################################################################################################################


3) Extracting the SRX information

You should pass a csv file with a GSM (samples) column as -d (--df_path) argument. You also should pass the directory with the downloaded XMLs files (-p, --path_xml argument). For each gsm the SRX information will be scrapped. The last argument (-o, --out_file_name) is the output file name. You should pass the path/output_file_name.

The command line: 
python main-srx.py -d $PATH/df_with_GSM_column.csv -p $PATH_DIR_XML_FILES -o $PATH/output_file_name.csv

To run via slurm:

#!/bin/bash
#SBATCH --time=03:00:00 # changeable
#SBATCH --account=
#SBATCH --cpus-per-task=4 #example
#SBATCH --mem=5G #example
#SBATCH --job-name=srx-xml


module load python/3.8.0
virtualenv --no-download $SLURM_TMPDIR/env
source $SLURM_TMPDIR/env/bin/activate
pip install --no-index --upgrade pip

pip install --no-index -r requirements.txt

python main-srx.py -d $PATH/df_with_GSM_column.csv -p $PATH_DIR_XML_FILES -o $PATH/DIR_RESULT/output_file_name (Do not put extension here)

-The output files will be chunked each 1000 lines. The complete output name file will be: output_file_name_chunck-0.tsv


######################################################################################################################################################


4) Extracting the SRR (access the raw data) information

The output files from SRX parser script will be passed here. The run_srr_chunck.sh files will be generated by create_srr_run.py. You also should pass a run_template.sh file as the third argument

To run create_srr_run.py:
python create_srr_run.py PATH/DIR_RESULT run_template.sh (you should adjust the run_template with your slurm information - account)


After run the create_srr.py you can submit all of the run_chunk.sh. The command line inserted in the .sh files is:

python $PATH/main-srr.py -p PATH/DIR_RESULT/srx_chuncked.tsv -o output.csv

Example run.sh file generated by create_srr.py:

#!/bin/bash
#SBATCH --time=24:00:00
#SBATCH --account=
#SBATCH --cpus-per-task=8
#SBATCH --mem=20G
#SBATCH --job-name=get-srr



module load python/3.8.0
virtualenv --no-download $SLURM_TMPDIR/env
source $SLURM_TMPDIR/env/bin/activate
pip install --no-index --upgrade pip

pip install --no-index -r /home/frosig/scratch/chip-seq-ihec-test/XML-files-webscrp/srrparser/requirements.txt
pip install retry

python $PATH/main-srr.py -p PATH/DIR_RESULT/srx_chuncked.tsv -o output.csv

For each run_chunk will be generated an srr_srx.output.csv. If you want to concatenate the srx_srr outputs you can run the concat-csv.sh script.





